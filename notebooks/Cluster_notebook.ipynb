{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cluster_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3710jvsc74a57bd09fdcff0f74d6f65ca11bcc249993ed75df2fbcf2fe9bd8864430df1d8786fd18",
      "display_name": "Python 3.7.10 64-bit ('TFenv': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "9fdcff0f74d6f65ca11bcc249993ed75df2fbcf2fe9bd8864430df1d8786fd18"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prikmm/MelDetect/blob/main/Cluster_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3-2gIkYNB-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6559f4-2cae-45c8-9a2c-efc27a35704b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g81RQagyRiQO",
        "outputId": "ed0c26d0-9665-4699-ed82-c2fd95f106bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q efficientnet >> /dev/null\n",
        "!pip install tensorflow-addons tensorflow-hub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 17.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 12.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 13.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 12.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 11.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (56.0.0)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gPS2hjWDZU"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/Meldetect_libraries')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZwn5RrzRgOA"
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "import tensorflow as tf, re, math\n",
        "import tensorflow.keras.backend as K\n",
        "import efficientnet.tfkeras as efn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import config\n",
        "config.REPLICAS, config.AUTO, config.strategy = config.tpu_gpu_initializer(DEVICE=\"GPU\")\n",
        "\n",
        "config.DATA_PATH = ['gs://kds-e587a221f0797cf8f017657b99d05aee1f262e04db020e07144fa268',\n",
        "                    'gs://kds-e587a221f0797cf8f017657b99d05aee1f262e04db020e07144fa268',\n",
        "                    'gs://kds-e587a221f0797cf8f017657b99d05aee1f262e04db020e07144fa268']\n",
        "\n",
        "\n",
        "config.DATA_PATH2 = ['gs://kds-daa129e989ec157e205de7addb63ac52a6bb066eb3efea7e285641dd',\n",
        "                    'gs://kds-daa129e989ec157e205de7addb63ac52a6bb066eb3efea7e285641dd',\n",
        "                    'gs://kds-daa129e989ec157e205de7addb63ac52a6bb066eb3efea7e285641dd']\n",
        "\n",
        "import models\n",
        "import datasets\n",
        "import images\n",
        "import callbacks\n",
        "import train"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not connect to TPU\nUsing default strategy for CPU and single GPU\nNum GPUs Available:  1\nREPLICAS: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZeDEaw4SbUC",
        "outputId": "a0e80ad4-cd00-4a85-832f-dc74d96d4f47"
      },
      "source": [
        "_, featext_model = models.build_model(\"efficientnet_b6\", return_feature_model=True)\n",
        "featext_model.load_weights(\"model/weights/efficientnet_b6/feat_efficientnet_b6.h5\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un2Y-PKah1p_",
        "outputId": "0a67f952-1d60-46e2-90b3-5dfb8eeb2776"
      },
      "source": [
        "SEED = 42\n",
        "INC2018 = [0, 0, 0]\n",
        "INC2019 = [1, 1, 1]\n",
        "FOLDS = 3\n",
        "VERBOSE = 2\n",
        "data_index = None\n",
        "data_train = None\n",
        "data_valid = None\n",
        "data_test = None\n",
        "IMG_SIZES = [384,384,384]\n",
        "BATCH_SIZES = [32]*FOLDS\n",
        "\n",
        "\n",
        "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n",
        "\n",
        "for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n",
        "    if fold != 2:\n",
        "        continue\n",
        "    data_index = fold\n",
        "    data_train = idxT\n",
        "    data_valid = idxV\n",
        "\n",
        "files_train = tf.io.gfile.glob([config.DATA_PATH[fold] + '/train%.2i*.tfrec'%x for x in data_train])\n",
        "if INC2019[fold]:\n",
        "    files_train += tf.io.gfile.glob([config.DATA_PATH2[fold] + '/train%.2i*.tfrec'%x for x in data_train*2+1])\n",
        "    print('#### Using 2019 external data')\n",
        "if INC2018[fold]:\n",
        "    files_train += tf.io.gfile.glob([config.config.DATA_PATH2[fold] + '/train%.2i*.tfrec'%x for x in data_train*2])\n",
        "    print('#### Using 2018+2017 external data')\n",
        "np.random.shuffle(files_train)\n",
        "files_valid = tf.io.gfile.glob([config.DATA_PATH[fold] + '/train%.2i*.tfrec'%x for x in data_valid])\n",
        "files_test = np.sort(np.array(tf.io.gfile.glob(config.DATA_PATH[fold] + '/test*.tfrec')))\n",
        "\n",
        "train_dataset = datasets.get_dataset(files_train, augment=True, shuffle=False, repeat=False,\n",
        "                            dim=IMG_SIZES[data_index],batch_size = BATCH_SIZES[data_index])\n",
        "\n",
        "#kmeans_log_path = os.path.join(os.curdir, \"kmeans_log\")\n",
        "#os.makedirs(kmeans_log_path, exist_ok=True)\n",
        "#num_clusters = 2\n",
        "#kmeans = tf.compat.v1.estimator.experimental.KMeans(\n",
        "#    num_clusters=num_clusters, model_dir=kmeans_log_path, use_mini_batch=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### Using 2019 external data\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Visualizing Image Embeddings using Tensorboard:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvwW1wOxm2bo"
      },
      "source": [
        "from tensorboard.plugins import projector\n",
        "import pickle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "STEPS = 500\n",
        "IMG_DIMS = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAG4siaOnuQi"
      },
      "source": [
        "feature_vecs = featext_model.predict(train_dataset)#, steps=STEPS)\n",
        "pickle.dump(part_feature_vecs, open('model/part_feature_vecs.pkl', 'wb'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1200 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ResizeBilinear: Dst tensor is not initialized. [Op:ResizeBilinear]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f3062333d7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mIMG_DIMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_DIMS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1645\u001b[0m       \u001b[0mpreserve_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreserve_aspect_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m       skip_resize_if_same=False)\n\u001b[0m\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresizer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# NOTE(mrry): The shape functions for the resize ops cannot unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_fn\u001b[0;34m(images_t, new_size)\u001b[0m\n\u001b[1;32m   1622\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         return gen_image_ops.resize_bilinear(\n\u001b[0;32m-> 1624\u001b[0;31m             images_t, new_size, half_pixel_centers=True)\n\u001b[0m\u001b[1;32m   1625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEAREST_NEIGHBOR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m       return gen_image_ops.resize_nearest_neighbor(\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mresize_bilinear\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3663\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3664\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3665\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3666\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/TFenv/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ResizeBilinear: Dst tensor is not initialized. [Op:ResizeBilinear]"
          ]
        }
      ],
      "source": [
        "images = None\n",
        "for item in train_dataset.take(1):\n",
        "    x, y = item\n",
        "    images = tf.image.resize(x[\"img_input\"], [IMG_DIMS, IMG_DIMS])\n",
        "    targets = y\n",
        "    \n",
        "# For Visualizing Image Quality\n",
        "plt.imshow(images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Appending rest of the images to the images tensor\n",
        "for batch_no, item in enumerate(train_dataset.take(STEPS)):\n",
        "    if batch_no == 0:\n",
        "        continue\n",
        "    x, y = item\n",
        "    resized_images = tf.image.resize(x[\"img_input\"], [IMG_DIMS, IMG_DIMS])\n",
        "    images = tf.concat([images, resized_images], 0)\n",
        "    targets = tf.concat([targets, y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(images.shape)\n",
        "print(targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfPHULma5tm"
      },
      "source": [
        "PATH = os.getcwd()\n",
        "LOG_DIR = PATH + '/embedding-tensorboard/log-1'\n",
        "metadata = os.path.join(LOG_DIR, 'metadata.tsv')\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "with open(metadata, 'w') as metadata_file:\n",
        "    for item in train_dataset.take(STEPS):\n",
        "        x, y = item\n",
        "        for i in range(x[\"metadata_input\"].shape[0]):\n",
        "            metadata_file.write('{}\\n'.format(tf.cast(y[i], tf.int8)))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHzGS5QBp7Dj"
      },
      "source": [
        "def images_to_sprite(data):\n",
        "    \"\"\"Creates the sprite image along with any necessary padding\n",
        "    Args:\n",
        "      data: NxHxW[x3] tensor containing the images.\n",
        "    Returns:\n",
        "      data: Properly shaped HxWx3 image with any necessary padding.\n",
        "    \"\"\"\n",
        "    if len(data.shape) == 3:\n",
        "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
        "    data = images_dum = np.array(images)\n",
        "    data = data.astype(np.float32)\n",
        "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
        "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
        "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
        "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
        "    # Inverting the colors seems to look better for MNIST\n",
        "    #data = 1 - data\n",
        "\n",
        "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
        "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
        "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
        "    data = np.pad(data, padding, mode='constant',\n",
        "            constant_values=0)\n",
        "    # Tile the individual thumbnails into an image.\n",
        "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
        "            + tuple(range(4, data.ndim + 1)))\n",
        "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
        "    data = (data * 255).astype(np.uint8)\n",
        "    return data"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btu3p9aWrZpG",
        "outputId": "2540709e-38a3-41ad-97c0-cd68a7ed42fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sprite = images_to_sprite(images)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc8Wk5fry5Ot",
        "outputId": "2b26faf6-ed72-434a-d8a4-0cfd0d905571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cv2.imwrite(os.path.join(LOG_DIR, 'sprite.png'), sprite)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"model/part_feature_vecs.pkl\",\"rb\") as reader:\n",
        "    part_feature_vecs = pickle.load(reader)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luHOCdFtvZus"
      },
      "source": [
        "features = tf.Variable(part_feature_vecs, name='feature')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([21789, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQvO_eL3stp1",
        "outputId": "421d28b5-af76-4c80-a7d7-8b2f3072109f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(embedding=features)\n",
        "checkpoint.save(os.path.join(LOG_DIR, \"embedding.ckpt\"))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/priyam145/MelDetect/embedding-tensorboard/log-1/embedding.ckpt-1'"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mys7M8gxmPFg"
      },
      "source": [
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "    # Link this tensor to its metadata file (e.g. labels).\n",
        "embedding.metadata_path =  'metadata.tsv'\n",
        "    # Comment out if you don't want sprites\n",
        "embedding.sprite.image_path =  'sprite.png'\n",
        "embedding.sprite.single_image_dim.extend([images.shape[1], images.shape[1]])\n",
        "    # Saves a config file that TensorBoard will read during startup.\n",
        "\n",
        "projector.visualize_embeddings(LOG_DIR, config)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsiHsdcz0kRV"
      },
      "source": [
        "valid_dataset = datasets.get_dataset(files_valid, augment=True, shuffle=False, repeat=False,\n",
        "                            dim=IMG_SIZES[data_index],batch_size = BATCH_SIZES[data_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzQu3e2eceVA"
      },
      "source": [
        "# train\n",
        "num_iterations = 10\n",
        "previous_centers = None\n",
        "for _ in range(num_iterations):\n",
        "    kmeans_input = featext_model.predict(train_dataset, steps=5)\n",
        "    print(kmeans_input)\n",
        "    print(kmeans_input.shape)\n",
        "    kmeans.train(kmeans_input)\n",
        "    cluster_centers = kmeans.cluster_centers()\n",
        "    if previous_centers is not None:\n",
        "        print('delta:', cluster_centers - previous_centers)\n",
        "previous_centers = cluster_centers\n",
        "print('score:', kmeans.score(input_fn))\n",
        "print('cluster centers:', cluster_centers)\n",
        "\n",
        "preds = kmeans.predict_index(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}